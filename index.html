<!DOCTYPE HTML PUBLIC "-//W3C//DTD HTML 4.01 Transitional//EN">
<html>

<head>
  <meta name=viewport content=“width=800”>
  <meta name="generator" content="HTML Tidy for Linux/x86 (vers 11 February 2007), see www.w3.org">
  <style type="text/css">
    /* Color scheme stolen from Sergey Karayev */
    
    a {
      color: #1772d0;
      text-decoration: none;
    }
    
    a:focus,
    a:hover {
      color: #f09228;
      text-decoration: none;
    }
    
    body,
    td,
    th,
    tr,
    p,
    a {
      font-family: 'Lato', Verdana, Helvetica, sans-serif;
      font-size: 14px
    }
    
    strong {
      font-family: 'Lato', Verdana, Helvetica, sans-serif;
      font-size: 14px;
    }
    
    heading {
      font-family: 'Lato', Verdana, Helvetica, sans-serif;
      font-size: 22px;
    }
    
    papertitle {
      font-family: 'Lato', Verdana, Helvetica, sans-serif;
      font-size: 14px;
      font-weight: 700
    }
    
    name {
      font-family: 'Lato', Verdana, Helvetica, sans-serif;
      font-size: 32px;
    }
    
    .one {
      width: 160px;
      height: 160px;
      position: relative;
    }
    
    .two {
      width: 160px;
      height: 160px;
      position: absolute;
      transition: opacity .2s ease-in-out;
      -moz-transition: opacity .2s ease-in-out;
      -webkit-transition: opacity .2s ease-in-out;
    }
    
    .fade {
      transition: opacity .2s ease-in-out;
      -moz-transition: opacity .2s ease-in-out;
      -webkit-transition: opacity .2s ease-in-out;
    }
    
    span.highlight {
      background-color: #ffffd0;
    }
  </style>
  <link rel="icon" type="image/png" href="icon.png">
  <title>Guanya Shi</title>
  <meta http-equiv="Content-Type" content="text/html; charset=us-ascii">
  <link href='http://fonts.googleapis.com/css?family=Lato:400,700,400italic,700italic' rel='stylesheet' type='text/css'>
</head>

<body>
  <table width="800" border="0" align="center" cellspacing="0" cellpadding="0">
    <tr>
      <td>
        <table width="100%" align="center" border="0" cellspacing="0" cellpadding="20">
          <tr>
            <td width="67%" valign="middle">
              <p align="center">
                <name>Guanya Shi 石冠亚</name>
              </p>
              <p>
              I am an incoming (Fall 2023) Assistant Professor in the <a href="https://ri.cmu.edu/">Robotics Institute</a> and the <a href="https://www.cs.cmu.edu/">School of Computer Science</a> at <a href="https://www.cmu.edu/">Carnegie Mellon University (CMU)</a>. I completed my Ph.D. in 2022 from <a href="http://www.caltech.edu">Caltech</a>, advised by <a href="http://aerospacerobotics.caltech.edu/">Soon-Jo Chung</a> and <a href="http://www.yisongyue.com/">Yisong Yue</a>. I received a B.E. from <a href="https://www.tsinghua.edu.cn/en/">Tsinghua University</a> in 2017. I was awarded the <a href="https://cms.caltech.edu/academics/honors#simoudis">Simoudis Discovery Prize</a> and the <a href="https://www.cms.caltech.edu/news-events/news/chou-doctoral-prize-in-ist-established">Ben P.C. Chou Doctoral Prize</a> at Caltech and was named a <a href="http://datascience.uchicago.edu/rising-stars/#rising-stars-profiles">Rising Star in Data Science</a> by the University of Chicago.
              </p>
              
              <p>
              I am currently a postdoctoral scholar in the <a href="https://www.cs.washington.edu/">Paul G. Allen School of Computer Science and Engineering (CSE)</a> at the <a href="https://www.washington.edu/">University of Washington</a> with <a href="https://homes.cs.washington.edu/~bboots/">Byron Boots</a>. I am broadly interested in the intersection of machine learning and control theory, spanning the entire spectrum from theory to real-world agile robotics.
              </p>

              <p align=center>
				        <a href="https://drive.google.com/file/d/1zwjK26dgouy9diFvVhvJ1fTsoCzi87j_/view?usp=sharing">CV</a> &nbsp/&nbsp
                <a href="mailto:guanyas@cs.washington.edu">Email</a> &nbsp/&nbsp
                <a href="https://www.gshi.me/blog/">Blog</a> &nbsp/&nbsp
                <a href="https://scholar.google.com/citations?user=joR1Z4UAAAAJ&hl=en&oi=ao">Google Scholar</a> &nbsp/&nbsp
                <a href="https://twitter.com/GuanyaShi">Twitter</a> &nbsp/&nbsp
                <a href="https://drive.google.com/file/d/1jKnpOO7L5J_y0_HGcvpqSm0fBJcO4OBM/view?usp=sharing"> Research Statement </a>
              </p>
            </td>
            <td width="33%">
              <img src="Guanya_Caltech.jpg" width='100%'>
            </td>
          </tr>
        </table>
        
        <hr>

        <table width="100%" align="center" border="0" cellspacing="0" cellpadding="20">
          <tr>
            <td width="100%" valign="middle">
              <p>
                <strong style="color:red;">News:</strong> Our <a href="https://www.science.org/doi/10.1126/scirobotics.abm6597">Neural-Fly</a> paper was accepted by <a href="https://www.science.org/journal/scirobotics">Science Robotics</a> and highlighted by <a href="https://youtu.be/R1S5BnKgJxs">Reuters</a> and <a href="https://www.cnn.com/videos/business/2022/05/31/caltech-neural-fly-drones-in-strong-wind-orig-ht.cnn-business/video/playlists/business-tech/">CNN</a>.
              </p>
              <p>
                <strong style="color:red;">News:</strong> I am co-organizing <a href="https://sites.google.com/view/control-meets-learning">Control Meets Learning</a>, a virtual seminar series on the intersection of control and learning.  
              </p>
<!--               <p>
                <strong style="color:red;">News:</strong> I was named a <a href="http://datascience.uchicago.edu/rising-stars/#rising-stars-profiles">Rising Star in Data Science</a> by the University of Chicago Center for Data and Computing.  
              </p> -->
<!--               <p>
                <strong style="color:red;">News:</strong> I was awarded the prestigious <a href="https://cms.caltech.edu/academics/honors#simoudis">Simoudis Discovery Prize</a> at Caltech CMS.  
              </p> -->
              <p>
                <strong style="color:red;">News:</strong> I opened a <a href="https://www.gshi.me/blog/">blog</a> focusing on control theory, machine learning, and robotics. Check it out!
              </p>
              <p>
                <strong style="color:red;">News:</strong> Two theory papers about meta-adaptive control and predictive control were accepted by <a href="https://nips.cc/">NeurIPS 2021</a>.  
              </p>              
              <p>
                <strong style="color:red;">News:</strong> Our <a href="https://arxiv.org/abs/2012.05457">Neural-Swarm2</a> paper was accepted by <a href="https://www.ieee-ras.org/publications/t-ro">IEEE Transactions on Robotics</a> (see the <a href="https://youtu.be/geJt8PFZ-Fk">close-proximity flight of 16 drones</a> and <a href="https://news.yahoo.com/caltech-drone-swarm-ai-174642584.html">Yahoo! news</a>). 
              </p>
	            <p>
                <strong style="color:red;">News:</strong> Our <a href="https://sites.google.com/view/fastuq">FastUQ</a> paper (my intern project at NVIDIA) was accepted by <a href="http://www.icra2021.org">ICRA 2021</a>.
              </p>
              <p>
                <strong style="color:red;">News:</strong> Two theory papers about competitive control and the regret analysis of MPC were accepted by <a href="https://nips.cc/">NeurIPS 2020</a>.  
              </p>
<!--               <p>
                <strong style="color:red;">News:</strong> Our Neural-Swarm paper was accepted by <a href="https://www.icra2020.org">ICRA 2020</a> and highlighed by <a href="https://www.caltech.edu/about/news/machine-learning-helps-robot-swarms-coordinate">Caltech news</a> and <a href="https://news.yahoo.com/caltech-drone-swarm-ai-174642584.html">Yahoo news</a>.
              </p> -->
<!--               <p>
                <strong style="color:red;">News:</strong> Interviewed by Facebook PyTorch team about learning and control research in robotic systems. [<a href="https://youtu.be/se206WBk2dM">video</a>]
              </p> -->
              <p>
                <strong style="color:red;">News:</strong> Our work on Neural Lander was accepted by <a href="https://www.icra2019.org">ICRA 2019</a> and highlighted by <a href="https://www.caltech.edu/about/news/neural-lander-uses-ai-land-drones-smoothly">Caltech</a>.
              </p>
	            <!--<p>
                <strong style="color:red;">News:</strong> Our work on Neural Lander was presented in <a href="http://phys2018.csail.mit.edu">Physics Workshop at NeurIPS 2018</a>.-->
              </p>    
            </td>
          </tr>
        </table>


        <table width="100%" align="center" border="0" cellspacing="0" cellpadding="20">
          <tr>
            <td width="100%" valign="middle">
              <heading>Research and Selected Publications</heading>
              <br>
              <br>
              <p>My interests are in the intersection of machine learning and control theory, spanning the entire spectrum from theory and foundations, algorithm design, to real-world applications in robotics and autonomy. To that end, my research has three goals: (1) bridge learning and control theory in a unified framework; (2) design reliable learning and control algorithms with formal guarantees; and (3) push the boundaries of agile robotic control with new capabilities. More details in my <a href="https://drive.google.com/file/d/1jKnpOO7L5J_y0_HGcvpqSm0fBJcO4OBM/view?usp=sharing">Research Statement</a>.</p>

              <p>For an up-to-date publication list, please see my <a href="https://drive.google.com/file/d/1zwjK26dgouy9diFvVhvJ1fTsoCzi87j_/view?usp=sharing">CV</a> or the <a href="https://scholar.google.com/citations?user=joR1Z4UAAAAJ&hl=en&oi=ao">Google Scholar</a> page. (*equal contribution, **alphabetical order)</p>
            </td>
          </tr>
        </table>

        <table width="100%" align="center" border="0" cellspacing="0" cellpadding="20">
          <tr>
            <td width="85%" valign="left">
              <papertitle><em>Neural-Control</em> Family: Stable and Robust Deep-learning-based Nonlinear Control in Dynamic Environments</papertitle> [<a href="https://www.gshi.me/blog/NeuralControl/">blog post</a>]
              <hr>
            </td>
          </tr>
        </table>

        <table width="100%" align="center" border="0" cellspacing="0" cellpadding="20">
          <tr>
            <td style="width:35%;vertical-align:middle">
              <img src='neural_lander.gif' width=100%>
            </td>
            <td style="width:65%;vertical-align:middle">
              <p>
                <a href="https://arxiv.org/abs/1811.08027">
                  <papertitle>Neural-Lander: Stable Drone Landing Control using Learned Dynamics</papertitle>
                </a>
                <br>
                <strong>Guanya Shi<sup>*</sup></strong>, <a href="https://scholar.google.com/citations?user=1oJrl8IAAAAJ&hl=en">Xichen Shi<sup>*</sup></a>, <a href="https://www.linkedin.com/in/mtoc12/">Michael O'Connell<sup>*</sup></a>, <a href="http://roseyu.com/">Rose Yu</a>, <a href="https://www.cs.purdue.edu/homes/kamyar/">Kamyar Azizzadenesheli</a>, <a href="http://tensorlab.cms.caltech.edu/users/anima/">Animashree Anandkumar</a>, <a href="http://www.yisongyue.com/">Yisong Yue</a>, <a href="http://aerospacerobotics.caltech.edu/">Soon-Jo Chung</a>
                <br>
                <em>International Conference on Robotics and Automation (ICRA)</em>, 2019
                <br>
                [<a href="https://arxiv.org/abs/1811.08027">arXiv</a>]
                [<a href="https://youtu.be/FLLsG0S78ik">video</a>]
                [<a href="https://www.caltech.edu/about/news/neural-lander-uses-ai-land-drones-smoothly">Caltech front page news</a>]
                [<a href="https://us13.campaign-archive.com/?u=67bd06787e84d73db24fb0aa5&id=6d61d65ae0&e=b8f2a6be0d">Import AI highlight</a>]
                [<a href="https://youtu.be/se206WBk2dM">PyTorch highlight</a>]
                [<a href="https://github.com/GuanyaShi/neural_lander_sim_1d">simulator code</a>]
                <br>
                <p></p>
                <p>We present a novel deep-learning-based robust nonlinear controller for stable quadrotor control during landing. Our approach blends together a nominal dynamics model coupled with a DNN that learns the high-order interactions, such as the complex interactions between the ground and multi-rotor airflow. This is the first DNN-based nonlinear feedback controller with stability guarantees that can utilize arbitrarily large neural nets. Neural-Lander enables agile drone maneuvers very close to the ground. 
                </p>
            </td>
          </tr>

          <tr>
            <td style="width:35%;vertical-align:middle">
              <img src='neural_swarm.gif' width='100%'>
            </td>
            <td style="width:65%;vertical-align:middle">
              <p>
                <a href="https://arxiv.org/abs/2012.05457">
                  <papertitle>Neural-Swarm: Heterogeneous Multi-Robot Control and Planning Using Learned Interactions</papertitle>
                </a>
                <br>
                <strong>Guanya Shi</strong>, <a href="https://scholar.google.com/citations?user=XUQcbFAAAAAJ&hl=en">Wolfgang Hoenig</a>, <a href="https://scholar.google.com/citations?user=1oJrl8IAAAAJ&hl=en">Xichen Shi</a>, <a href="http://www.yisongyue.com/">Yisong Yue</a>, <a href="http://aerospacerobotics.caltech.edu/">Soon-Jo Chung</a>
                <br>
                <em>International Conference on Robotics and Automation (ICRA)</em>, 2020
                <br>
                <em>IEEE Transactions on Robotics (T-RO)</em>, 2021
                <br>
                [<a href="https://arxiv.org/abs/2012.05457">arXiv</a>]
                [<a href="https://youtu.be/Y02juH6BDxo">video</a>]
                [<a href="https://www.caltech.edu/about/news/machine-learning-helps-robot-swarms-coordinate">Caltech news</a>]
                [<a href="https://news.yahoo.com/caltech-drone-swarm-ai-174642584.html">Yahoo! news</a>]
                [<a href="https://github.com/aerorobotics/neural-swarm">data & code</a>]
                <br>
                <p></p>
                <p>Close-proximity control and planning are challenging due to the complex aerodynamic effects between multirotors. We proposed Neural-Swarm, a nonlinear decentralized stable learning-based controller and motion planner for close-proximity flight of heterogeneous multirotor swarms. We develop and employ heterogeneous deep sets to encode multi-vehicle interactions in an index-free manner, enabling better generalization. Neural-Swarm enables close-proximity flight with 24 cm minimum vertical distance for a heterogeneous aerial team with 16 robots.</p>
            </td>
          </tr>

          <tr>
            <td style="width:35%;vertical-align:middle">
              <img src='neural_fly.gif' width='100%'>
            </td>
            <td style="width:65%;vertical-align:middle">
              <p>
                <a href="https://www.science.org/doi/10.1126/scirobotics.abm6597">
                  <papertitle>Neural-Fly Enables Rapid Learning for Agile Flight in Strong Winds</papertitle>
                </a>
                <br>
                <a href="https://www.linkedin.com/in/mtoc12/">Michael O'Connell<sup>**</sup></a>, <strong>Guanya Shi<sup>**</sup></strong>, <a href="https://scholar.google.com/citations?user=1oJrl8IAAAAJ&hl=en">Xichen Shi</a>, <a href="https://www.cs.purdue.edu/homes/kamyar/">Kamyar Azizzadenesheli</a>, <a href="http://tensorlab.cms.caltech.edu/users/anima/">Animashree Anandkumar</a>, <a href="http://www.yisongyue.com/">Yisong Yue</a>, <a href="http://aerospacerobotics.caltech.edu/">Soon-Jo Chung</a>
                <br>
                <em>Science Robotics</em>, 2022 <!-- (<strong>cover article</strong>) -->
                <br>
                [<a href="https://www.science.org/doi/10.1126/scirobotics.abm6597">paper</a>]
                [<a href="https://youtu.be/TuF9teCZX0U">video</a>]
                [<a href="https://www.caltech.edu/about/news/rapid-adaptation-of-deep-learning-teaches-drones-to-survive-any-weather">Caltech front page news</a>]
                [<a href="https://arxiv.org/abs/2205.06908">arXiv</a>]
                [<a href="https://github.com/aerorobotics/neural-fly">code & data</a>]
                [<a href="https://youtu.be/R1S5BnKgJxs">Reuters news</a>]
                [<a href="https://www.cnn.com/videos/business/2022/05/31/caltech-neural-fly-drones-in-strong-wind-orig-ht.cnn-business/video/playlists/business-tech/">CNN news</a>]
                <!-- [<a href="https://youtu.be/tCRUhNj4R04">demo video: a drone in CAST fan wall</a>] -->
                <br>
                <!--<em>Submitted to ICRA 2020</em>-->
                <!--
                <br>
                <a href="https://drive.google.com/open?id=1WgW6Ym84dxv95-KQQy5X27W5kFNp7KMq">[<strong>video</strong>]</a>
                <a href="https://drive.google.com/open?id=1no4olzlgqA7kc60b7V2pkXqFjxY2H3Ds">[<strong>pdf</strong>]</a>
                <br>-->
                <p></p>
                <p>Deep learning has representation power but is often too slow to update onboard. On the other hand, adaptive control with linear parametric uncertainty can update as fast as the feedback control loop. We propose an online stable and robust adaptation method that treats outputs from a DNN as a set of basis functions capable of representing different environments. A novel Domain Adversarially Invariant Meta-Learning (DAIML) algorithm is developed to train the network. Neural-Fly enables agile flights in unknown time-variant wind conditions.</p>
            </td>
          </tr>
        </table>

        <table width="100%" align="center" border="0" cellspacing="0" cellpadding="20">
          <tr>
            <td width="85%" valign="left">
              <papertitle>Foundations of Online Learning and Control Theory</papertitle>
              <hr>
            </td>
          </tr>
        </table>

        <table width="100%" align="center" border="0" cellspacing="0" cellpadding="20">
          <tr>
            <td style="width:30%;vertical-align:middle">
              <img src='OMAC.gif' width='100%'>
            </td>
            <td style="width:70%;vertical-align:middle">
              <p>
                <a href="https://arxiv.org/abs/2106.06098">
                  <papertitle>Meta-Adaptive Nonlinear Control: Theory and Algorithms</papertitle>
                </a>
                <br>
                <strong>Guanya Shi</strong>, <a href="https://www.cs.purdue.edu/homes/kamyar/">Kamyar Azizzadenesheli</a>, <a href="https://www.linkedin.com/in/mtoc12/">Michael O'Connell</a>, <a href="http://aerospacerobotics.caltech.edu/">Soon-Jo Chung</a>, <a href="http://www.yisongyue.com/">Yisong Yue</a>
                <br>
                <em>Neural Information Processing Systems (NeurIPS)</em>, 2021
                <br>
                [<a href="https://arxiv.org/abs/2106.06098">arXiv</a>]
                [<a href="https://github.com/GuanyaShi/Online-Meta-Adaptive-Control">code & video</a>]
                <br>
                <p></p>
                <p>We present an online multi-task learning approach for adaptive nonlinear control, Online Meta-Adaptive Control (OMAC). The goal is to control a nonlinear system subject to adversarial disturbance and unknown <em>environment-dependent</em> nonlinear dynamics, under the assumption that the environment-dependent dynamics can be well captured with some shared representation. OMAC provides the first non-asymptotic end-to-end convergence guarantee for multi-task control. OMAC can also be integrated with deep representation learning.
                </p>
            </td>
          </tr>

          <tr>
            <td style="width:30%;vertical-align:middle">
              <img src='optimistic_robd.png' width='100%'>
            </td>
            <td style="width:70%;vertical-align:middle">
              <p>
                <a href="https://arxiv.org/abs/2002.05318">
                  <papertitle>Online Optimization with Memory and Competitive Control</papertitle>
                </a>
                <br>
                <strong>Guanya Shi<sup>*</sup></strong>, <a href="https://scholar.google.com/citations?user=S1wSEggAAAAJ&hl=en">Yiheng Lin<sup>*</sup></a>, <a href="http://aerospacerobotics.caltech.edu/">Soon-Jo Chung</a>, <a href="http://www.yisongyue.com/">Yisong Yue</a>, <a href="http://users.cms.caltech.edu/~adamw/index.html">Adam Wierman</a>
                <br>
                <em>Neural Information Processing Systems (NeurIPS)</em>, 2020
                <br>
                [<a href="https://arxiv.org/abs/2002.05318">arXiv</a>]
		            [<a href="https://crossminds.ai/video/5fb82261890833803bc7e7f3/">NeurIPS video</a>]
                <br>
                <p></p>
                <p>We present competitive algorithms for a novel class of online optimization problems with memory. We consider a setting where the learner seeks to minimize the sum of a hitting cost and a switching cost that depends on the previous <em>p</em> decisions. The proposed approach, Optimistic ROBD, achieves aconstant, dimension-free competitive ratio. Further, we show a connection between online optimization with memory and online control with adversarial disturbances. This connection leads to a new constant-competitive policy for a rich class of online control problems.</p>
            </td>
          </tr>

          <tr>
            <td style="width:30%;vertical-align:middle">
              <img src='power_of_predictions.png' width='100%'>
            </td>
            <td style="width:70%;vertical-align:middle">
              <p>
                <a href="https://arxiv.org/abs/2006.07569">
                  <papertitle>The Power of Predictions in Online Control</papertitle>
                </a>
                <br>
                <a href="https://ckyu.me/">Chenkai Yu</a>, <strong>Guanya Shi</strong>, <a href="http://aerospacerobotics.caltech.edu/">Soon-Jo Chung</a>, <a href="http://www.yisongyue.com/">Yisong Yue</a>, <a href="http://users.cms.caltech.edu/~adamw/index.html">Adam Wierman</a>
                <br>
                <em>Neural Information Processing Systems (NeurIPS)</em>, 2020
                <br>
                [<a href="https://arxiv.org/abs/2006.07569">arXiv</a>]
				[<a href="https://videos.neurips.cc/search/power%20of%20predictions%20in%20online%20control/video/slideslive-38936069">NeurIPS video</a>]
				[<a href="https://www.gshi.me/blog/CompetitiveMPC/">blog post</a>]
                <br>
                <p></p>
                <p>We study the impact of predictions in online LQR control with both stochastic and adversarial disturbances in the dynamics. In both settings, we characterize the optimal policy and derive tight bounds on the minimum cost and dynamic regret. Our analysis shows that the conventional MPC approach is a near-optimal policy in both settings. Specifically, for length-<em>T</em> problems, MPC requires <em>O</em>(log<em>T</em>) predictions to reach <em>O</em>(1) dynamic regret, which matches our lower bound on the required prediction horizon for constant regret. This result gives the first non-asymptotic guarantee for MPC.</p>
            </td>
          </tr>

          <tr>
            <td style="width:30%;vertical-align:middle">
              <img src='perturbation_mpc.png' width='100%'>
            </td>
            <td style="width:70%;vertical-align:middle">
              <p>
                <a href="https://proceedings.neurips.cc/paper/2021/file/298f587406c914fad5373bb689300433-Paper.pdf">
                  <papertitle>Perturbation-Based Regret Analysis of Predictive Control in LTV Systems</papertitle>
                </a>
                <br>
                <a href="https://scholar.google.com/citations?user=S1wSEggAAAAJ&hl=en&oi=ao">Yiheng Lin<sup>*</sup></a>, Yang Hu<sup>*</sup>, <strong>Guanya Shi<sup>*</sup></strong>, <a href="https://www.linkedin.com/in/sun-haoyuan/">Haoyuan Sun<sup>*</sup></a>, <a href="http://www.guannanqu.com">Guannan Qu<sup>*</sup></a>, <a href="http://users.cms.caltech.edu/~adamw/index.html">Adam Wierman</a>
                <br>
                <em>(<strong>spotlight</strong>, <3% of submissions) Neural Information Processing Systems (NeurIPS)</em>, 2021
                <br>
                [<a href="https://proceedings.neurips.cc/paper/2021/file/298f587406c914fad5373bb689300433-Paper.pdf">pdf</a>]
                [<a href="https://www.gshi.me/blog/CompetitiveMPC/">blog post</a>]
                <br>
                <p></p>
                <p>We study predictive control in linear time-varying (LTV) systems, and the costs are also time-varying. At each time step, the controller receives the exact predictions of costs, dynamics, and disturbances for the future <em>k</em> time steps. We show that MPC achieves a dynamic regret of <em>O</em>(<em>λ<sup>k</sup>T</em>), where <em>λ</em><1 is a positive constant. We also show that MPC obtains the first competitive bound for the control of LTV systems: 1+<em>O</em>(<em>λ<sup>k</sup></em>). Our results are derived using a novel proof framework based on a perturbation bound that characterizes how a small change to the system parameters impacts the optimal trajectory.</p>
            </td>
          </tr>

          <!--
          <tr>
            <td style="width:30%;vertical-align:middle">
              <img src='delayed_imperfect_information.png' width='100%'>
            </td>
            <td style="width:70%;vertical-align:middle">
              <p>
                <a href="https://arxiv.org/abs/2010.11637">
                  <papertitle>Competitive Control with Delayed Imperfect Information</papertitle>
                </a>
                <br>
                <a href="https://ckyu.me/">Chenkai Yu</a>, <strong>Guanya Shi</strong>, <a href="http://aerospacerobotics.caltech.edu/">Soon-Jo Chung</a>, <a href="http://www.yisongyue.com/">Yisong Yue</a>, <a href="http://users.cms.caltech.edu/~adamw/index.html">Adam Wierman</a>
                <br>
                <em>preprint</em>
                <br>
                [<a href="https://arxiv.org/abs/2010.11637">arXiv</a>]
                <br>
                <p></p>
                <p>This paper studies the impact of imperfect information in online control with adversarial disturbances. In particular, we consider both delayed state feedback and inexact predictions of future disturbances. We introduce a greedy, myopic policy that yields a constant competitive ratio against the offline optimal policy with delayed feedback and inexact predictions. A special case of our result is a constant competitive policy for the case of exact predictions and no delay, a previously open problem. We also analyze the fundamental limits of online control with limited information by showing that our competitive ratio bounds for the greedy, myopic policy in the adversarial setting match (up to lower-order terms) lower bounds in the stochastic setting. </p>
            </td>
          </tr>
          -->

        </table>

        <table width="100%" align="center" border="0" cellspacing="0" cellpadding="20">
          <tr>
            <td width="85%" valign="left">
              <papertitle>Uncertainty Quantification and Safe Explorations in Dynamical Systems</papertitle>
              <hr>
            </td>
          </tr>
        </table>

        <table width="100%" align="center" border="0" cellspacing="0" cellpadding="20">
          <tr>
            <td style="width:30%;vertical-align:middle">
              <img src='fast_uq.png' width='100%'>
            </td>
            <td style="width:70%;vertical-align:middle">
              <p>
                <a href="https://sites.google.com/view/fastuq">
                  <papertitle>Fast Uncertainty Quantification for Deep Object Pose Estimation</papertitle>
                </a>
                <br>
                <strong>Guanya Shi</strong>, <a href="https://zhuyifengzju.github.io/">Yifeng Zhu</a>, <a href="https://scholar.google.ca/citations?user=zeS5UJEAAAAJ&hl=en">Jonathan Tremblay</a>, <a href="https://research.nvidia.com/person/stan-birchfield">Stan Birchfield</a>, <a href="https://fabioramos.github.io/Home.html">Fabio Ramos</a>, <a href="http://tensorlab.cms.caltech.edu/users/anima/">Animashree Anandkumar</a>, <a href="https://www.cs.utexas.edu/~yukez/">Yuke Zhu</a>
                <br>
                <em>International Conference on Robotics and Automation (ICRA)</em>, 2021
                <br>
                [<a href="https://arxiv.org/abs/2011.07748">arXiv</a>]
                [<a href="https://sites.google.com/view/fastuq">project website</a>]
                [<a href="https://github.com/NVlabs/DOPE-Uncertainty">code</a>]
                [<a href="https://developer.nvidia.com/blog/nvidia-research-fast-uncertainty-quantification-for-deep-object-pose-estimation/">Nvidia developer blog</a>]
                <br>
                <p></p>
                <p>Deep learning-based object pose estimators are often unreliable and overconfident especially with sim2real transfer. In this work, we propose a simple, efficient, and plug-and-play UQ method for 6-DoF object pose estimation. We ensemble pre-trained models with different neural network architectures and/or training data sources, and compute their average pairwise disagreement against one another to obtain the uncertainty quantification. Our UQ method yields much stronger correlations with pose estimation errors than the baselines in three tasks. Moreover, in a real robot grasping task, our method increases the grasping success rate from 35% to 90%.</p>
            </td>
          </tr>          

          <tr>
            <td style="width:30%;vertical-align:middle">
              <img src='robust_regression.png' width='100%'>
            </td>
            <td style="width:70%;vertical-align:middle">
              <p>
                <a href="https://arxiv.org/pdf/1906.05819">
                  <papertitle>Robust Regression for Safe Exploration in Control</papertitle>
                </a>
                <br>
                <a href="https://anqiliu-ai.github.io">Anqi Liu</a>, <strong>Guanya Shi</strong>, <a href="http://aerospacerobotics.caltech.edu/">Soon-Jo Chung</a>, <a href="http://tensorlab.cms.caltech.edu/users/anima/">Animashree Anandkumar</a>, <a href="http://www.yisongyue.com/">Yisong Yue</a>
                <br>
                <em>Conference on Learning for Dynamics and Control (L4DC)</em>, 2020
                <br>
                [<a href="https://arxiv.org/pdf/1906.05819">arXiv</a>]
                <br>
                <p></p>
                <p>We study the problem of safe learning and exploration in sequential control problems. The goal is to safely collect data samples from operating in an environment, in order to learn to achieve a challenging control goal (e.g., an agile maneuver close to a boundary). We present a deep robust regression model that is trained to directly predict the uncertainty bounds for safe exploration. We derive generalization bounds for learning under domain shift and connect them with safety and stability bounds in control. Our approach outperforms the conventional Gaussian process (GP) based safe exploration in settings where it is difficult to specify a good GP prior.</p>
            </td>
          </tr>

          <tr>
            <td style="width:30%;vertical-align:middle">
              <img src='info_snoc.png' width='100%'>
            </td>
            <td style="width:70%;vertical-align:middle">
              <p>
                <a href="https://arxiv.org/abs/2005.04374">
                  <papertitle>Chance-Constrained Trajectory Optimization for Safe Exploration and Learning of Nonlinear Systems</papertitle>
                </a>
                <br>
                <a href="https://yashwanthnakka.com/">Yashwanth Kumar Nakka</a>, <a href="https://anqiliu-ai.github.io">Anqi Liu</a>, <strong>Guanya Shi</strong>, <a href="http://tensorlab.cms.caltech.edu/users/anima/">Animashree Anandkumar</a>, <a href="http://www.yisongyue.com/">Yisong Yue</a>, <a href="http://aerospacerobotics.caltech.edu/">Soon-Jo Chung</a>
                <br>
                <em>IEEE Robotics and Automation Letters (RA-L)</em>, 2020
                <br>
                [<a href="https://arxiv.org/abs/2005.04374">arXiv</a>]
                [<a href="https://yashwanthnakka.com/blog/">blog</a>]
                <br>
                <p></p>
                <p>We present a new approach for optimal motion planning with safe exploration that integrates chance-constrained stochastic optimal control with dynamics learning and feedback control. We derive an iterative convex optimization algorithm that solves an Information-cost Stochastic Nonlinear Optimal Control problem (Info-SNOC). The optimization objective encodes both optimal performance and exploration for learning, and the safety is incorporated as distributionally robust chance constraints. We prove the safety of rollout from our exploration method and reduction in uncertainty over epochs, thereby guaranteeing the consistency of our learning method. Our approach has higher success rate in ensuring safety when compared to a deterministic trajectory optimization approach.</p>
            </td>
          </tr>
          </table>

        <hr>

	<!--
        <table width="100%" align="center" border="0" cellspacing="0" cellpadding="20">
          <tr>
            <td>
              <heading>Teaching</heading>
            </td>
          </tr>
        </table>

        <table width="100%" align="center" border="0" cellpadding="20">
          <tr>
            <td width="100%" valign="middle">
            <p>
            <a href="http://tensorlab.cms.caltech.edu/users/anima/cms165-2020.html">
                  <papertitle>CS/CNS/EE/IDS 165: Foundations of Machine Learning and Statistical Inference, Caltech</papertitle></a>
            </p>
            </td>
          </tr>
        </table>

        <table width="100%" align="center" border="0" cellspacing="0" cellpadding="20">
          <tr>
            <td>
              <heading>Talks and Activities</heading>
            </td>
          </tr>
        </table>

        <table width="100%" align="center" border="0" cellpadding="20">
          <tr>
            <td width="100%" valign="middle">
            <p>
            "Using Deep Learning and PyTorch to Power Next Generation Aircraft at Caltech", interviewed by Facebook PyTorch team about learning and control research in robotic systems. [<a href="https://youtu.be/se206WBk2dM">video</a>]
            </p>
            </td>
          </tr>
        </table>

        <table width="100%" align="center" border="0" cellspacing="0" cellpadding="20">
          <tr>
            <td>
              <heading>Conference and Journal Reviewing</heading>
            </td>
          </tr>
        </table>

        <table width="100%" align="center" border="0" cellpadding="20">
          <tr>
            <td width="100%" valign="middle">
            <p>
            <papertitle>Conference:</papertitle> ICML 2020, NeurIPS 2020, ICRA 2019-2020, IROS 2020, CoRL 2020, ICLR 2021
            </p>
            <p>
            <papertitle>Journal:</papertitle> IEEE Transaction on Automatic Control (TAC)
            </p>
            </td>
          </tr>
        </table>

        <table width="100%" align="center" border="0" cellspacing="0" cellpadding="20">
          <tr>
            <td>
              <heading>Other Fun Projects</heading>
            </td>
          </tr>
        </table>

        <table width="100%" align="center" border="0" cellpadding="20">
          <tr>
            <td width="25%"><img src="mario.png" alt="prl" width="190" height="190"></td>
            <td width="75%" valign="top">
              <p>
                <a href="https://github.com/GuanyaShi/Training-DQN-to-play-Super-Mario-Bros">
                  <papertitle>Teaching Mario to Play Mario: Reinforcement Learning on <em>Super Mario Bros</em>.</papertitle>
                </a>
                <br>
                <strong>Guanya Shi</strong>, <a href="https://sites.google.com/view/botaohu">Botao Hu</a>, <a href="https://www.linkedin.com/in/echoyw/">Yan Wu</a>
                <p>
                  <br> Final project of <a href="https://sites.google.com/view/cs-159-spring-2018/home">Caltech CS 159</a>. We present a deep learning model to successfully learn control policies from high-dimensional input data using reinforcement learning. The model is based on the idea of Deep Q-Network (DQN), with convolutional neural network trained by Q-learning algorithm, whose input is tile representation of the screen and output is a value estimation function. Also, replay buffer, target network and double Q-learning are applied to lower data dependency and approximate real gradiant descent.
                </p>
              </p>
            </td>
          </tr>
        </table>
  
        <hr>
  		-->
  
        <table width="100%" align="center" border="0" cellspacing="0" cellpadding="20">
          <tr>
            <td>
              <heading>Misc.</heading>
              <p>
                I love playing basketball, soccer and MOBA games. I am also very interested in photography, hiking, travelling and cooking. Here are some photos taken by me. Feel free to email me if you are interested in these photos.
<!--                 Representative papers are <span class="highlight">highlighted</span>.
 -->          </p>
            </td>
          </tr>
        </table>
        <table width="100%" align="center" border="0" cellpadding="20">
            <td width="50%"><img src="12.jpg" alt="prl" width="360" height="216"></td>
            <td width="50%"><img src="13.jpg" alt="prl" width="360" height="216"></td>
        </table>
        <table width="100%" align="center" border="0" cellpadding="10">
            <td width="100%" align="center">A drone flying in the Caltech Real Weather Wind Tunnel (Neural-Fly project)</td>
        </table>
        <table width="100%" align="center" border="0" cellpadding="20">
            <td width="50%"><img src="3.jpeg" alt="prl" width="360" height="216"></td>
            <td width="50%"><img src="10.jpg" alt="prl" width="360" height="216"></td>
        </table>
        <table width="100%" align="center" border="0" cellpadding="10">
            <td width="50%" align="center">Beijing National Stadium</td>
            <td width="50%" align="center">Caltech Beckman Auditorium</td>
        </table>
        <table width="100%" align="center" border="0" cellpadding="20">
            <td width="50%"><img src="5.jpeg" alt="prl" width="360" height="216"></td>
            <td width="50%"><img src="6.jpeg" alt="prl" width="360" height="216"></td>
        </table>
        <table width="100%" align="center" border="0" cellpadding="10">
            <td width="50%" align="center">Wudaokou, Beijing</td>
            <td width="50%" align="center">Tokugawaen, Nagoya, Japan</td>
        </table>
        <table width="100%" align="center" border="0" cellpadding="20">
            <td width="50%"><img src="1.jpeg" alt="prl" width="360" height="216"></td>
            <td width="50%"><img src="8.jpeg" alt="prl" width="360" height="216"></td>
        </table>
        <table width="100%" align="center" border="0" cellpadding="10">
            <td width="50%" align="center">Winter Tsinghua</td>
            <td width="50%" align="center">Yosemite, California</td>
        </table>

        <hr>
  
        <table width="80%" align="left" border="0" cellspacing="0" cellpadding="20">
          <tr>
            <td>
              <br>
              <p align="left">
                <font size="2">
                  Based on <a href="https://jonbarron.info/">this website</a>.
                  </font>
              </p>
            </td>
          </tr>
        </table>
        <table width="20%" align="right" border="0" cellspacing="0" cellpadding="20">
        <script type='text/javascript' id='clustrmaps' src='//cdn.clustrmaps.com/map_v2.js?cl=ffffff&w=a&t=tt&d=UeP4z9v03sHtkGGcNgcJaLLOYl7Tm5OQqbSpW6HSGcI'></script>
		<!-- <script type="text/javascript" id="clustrmaps" src="//cdn.clustrmaps.com/map_v2.js?d=UeP4z9v03sHtkGGcNgcJaLLOYl7Tm5OQqbSpW6HSGcI&cl=ffffff&w=a"></script> -->
        <script type="text/javascript">
          var gaJsHost = (("https:" == document.location.protocol) ? "https://ssl." : "http://www.");
          document.write(unescape("%3Cscript src='" + gaJsHost + "google-analytics.com/ga.js' type='text/javascript'%3E%3C/script%3E"));
        </script>
        <script type="text/javascript">
          try {
            var pageTracker = _gat._getTracker("UA-7580334-1");
            pageTracker._trackPageview();
          } catch (err) {}
        </script>
        </td>
    </tr>
  </table>
</body>

</html>
